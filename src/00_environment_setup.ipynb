{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsv4jGuU89rX"
   },
   "source": [
    "# FraudFinder - Environment Setup\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/fraudfinder/raw/main/00_environment_setup.ipynb\">\n",
    "       <img src=\"https://www.gstatic.com/cloud/images/navigation/vertex-ai.svg\" alt=\"Google Cloud Notebooks\">Open in Cloud Notebook\n",
    "    </a>\n",
    "  </td> \n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/fraudfinder/blob/main/00_environment_setup.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/fraudfinder/blob/main/00_environment_setup.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "827c41ab1a12"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[FraudFinder](https://github.com/googlecloudplatform/fraudfinder) is a series of labs on how to build a real-time fraud detection system on Google Cloud. Throughout the FraudFinder labs, you will learn how to read historical bank transaction data stored in data warehouse, read from a live stream of new transactions, perform exploratory data analysis (EDA), do feature engineering, ingest features into a feature store, train a model using feature store, register your model in a model registry, evaluate your model, deploy your model to an endpoint, do real-time inference on your model with feature store, and monitor your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45f6e923dc75"
   },
   "source": [
    "### Objective\n",
    "\n",
    "Before you run this notebook, make sure that you have completed the steps in [README](README.md).\n",
    "\n",
    "In this notebook, you will setup your environment for Fraudfinder to be used in subsequent labs.\n",
    "\n",
    "This lab uses the following Google Cloud services and resources:\n",
    "\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai/)\n",
    "- [BigQuery](https://cloud.google.com/bigquery/)\n",
    "- [Google Cloud Storage](https://cloud.google.com/storage)\n",
    "- [Pub/Sub](https://cloud.google.com/pubsub/)\n",
    "\n",
    "Steps performed in this notebook:\n",
    "\n",
    "- Setup your environment.\n",
    "- Load historical bank transactions into BigQuery.\n",
    "- Read data from BigQuery tables.\n",
    "- Read data from Pub/Sub topics, which contain a live stream of new transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b5e2e2a7bdb"
   },
   "source": [
    "### Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04c1dae4ca17"
   },
   "source": [
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "* Pub/Sub\n",
    "* BigQuery\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), [Pub/Sub pricing](https://cloud.google.com/pubsub/pricing), [BigQuery pricing](https://cloud.google.com/bigquery/pricing) and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "773901ca47fd"
   },
   "source": [
    "### Install additional packages\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b7c7ce6bbf03",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-pubsub<=2.18.4 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.13.6)\n",
      "Collecting google-cloud-pubsub<=2.18.4 (from -r requirements.txt (line 1))\n",
      "  Downloading google_cloud_pubsub-2.18.4-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-cloud-bigquery<=3.13.0 (from -r requirements.txt (line 2))\n",
      "  Downloading google_cloud_bigquery-3.13.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<=2.22.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.16.2)\n",
      "Collecting google-cloud-bigquery-storage<=2.22.0 (from -r requirements.txt (line 3))\n",
      "  Downloading google_cloud_bigquery_storage-2.22.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-aiplatform<=1.36.1 (from -r requirements.txt (line 5))\n",
      "  Downloading google_cloud_aiplatform-1.36.1-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Collecting google-cloud-pipeline-components<=0.3.0 (from -r requirements.txt (line 6))\n",
      "  Downloading google_cloud_pipeline_components-0.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: plotly<=5.18.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (5.10.0)\n",
      "Collecting plotly<=5.18.0 (from -r requirements.txt (line 7))\n",
      "  Downloading plotly-5.18.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: xgboost<=2.0.1 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.6.2)\n",
      "Collecting xgboost<=2.0.1 (from -r requirements.txt (line 8))\n",
      "  Downloading xgboost-2.0.1-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting kfp<=2.3.0 (from -r requirements.txt (line 9))\n",
      "  Downloading kfp-2.3.0.tar.gz (377 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting apache_beam==2.53.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading apache_beam-2.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.11.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.11.1)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.73.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.20.4)\n",
      "Collecting js2py<1,>=0.74 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.24.0)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.22.4)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (25.0)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.26.1)\n",
      "Collecting protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2025.2)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2024.11.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.14.1)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.23.0)\n",
      "Requirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (7.0.0)\n",
      "Collecting pyarrow-hotfix<1 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=3.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.2.4)\n",
      "Requirement already satisfied: google-api-core<3,>=2.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.8.2)\n",
      "Collecting google-apitools<0.5.32,>=0.5.31 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.40.3)\n",
      "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.1.1)\n",
      "Collecting google-cloud-datastore<3,>=2.0.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_datastore-2.21.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.12.0)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=2.10.0 in /home/jupyter/.local/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.4.3)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_bigtable-2.31.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.46.0)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.18.0)\n",
      "Collecting google-cloud-language<3,>=2.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_language-2.17.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_videointelligence-2.16.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: google-cloud-vision<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.7.2)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.7.1)\n",
      "Collecting google-api-core<3,>=2.0.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-pubsub<=2.18.4->-r requirements.txt (line 1)) (0.12.7)\n",
      "Requirement already satisfied: grpcio-status>=1.33.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-pubsub<=2.18.4->-r requirements.txt (line 1)) (1.49.0rc1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-bigquery<=3.13.0->-r requirements.txt (line 2)) (2.7.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-aiplatform<=1.36.1->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-aiplatform<=1.36.1->-r requirements.txt (line 5)) (2.1.1)\n",
      "INFO: pip is looking at multiple versions of google-cloud-pipeline-components to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-pipeline-components<=0.3.0 (from -r requirements.txt (line 6))\n",
      "  Downloading google_cloud_pipeline_components-0.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.5-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.1-1-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "INFO: pip is still looking at multiple versions of google-cloud-pipeline-components to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_cloud_pipeline_components-0.1.9-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.8-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.7-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.5-py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading google_cloud_pipeline_components-0.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting kfp<=2.3.0 (from -r requirements.txt (line 9))\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from plotly<=5.18.0->-r requirements.txt (line 7)) (9.1.2)\n",
      "Requirement already satisfied: scipy in /home/jupyter/.local/lib/python3.10/site-packages (from xgboost<=2.0.1->-r requirements.txt (line 8)) (1.13.1)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (6.0.2)\n",
      "Collecting kubernetes<26,>=8.0.0 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading kubernetes-25.3.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-api-python-client<2,>=1.7.8 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (0.10.1)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (8.2.1)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (1.2.18)\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading strip_hints-0.1.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (0.16)\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.16 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl.metadata (323 bytes)\n",
      "Collecting fire<1,>=0.3.1 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting uritemplate<4,>=3.0.1 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: urllib3<2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (1.26.20)\n",
      "Collecting pydantic<2,>=1.8.2 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading pydantic-1.10.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (154 kB)\n",
      "Collecting typer<1.0,>=0.3.2 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from Deprecated<2,>=1.2.7->kfp<=2.3.0->-r requirements.txt (line 9)) (1.17.2)\n",
      "Requirement already satisfied: termcolor in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from fire<1,>=0.3.1->kfp<=2.3.0->-r requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-core<3,>=2.0.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.63.1)\n",
      "Requirement already satisfied: six<2dev,>=1.13.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-python-client<2,>=1.7.8->kfp<=2.3.0->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-apitools<0.5.32,>=0.5.31->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.1.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.9.1)\n",
      "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.7.1)\n",
      "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (7.7.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.5.3)\n",
      "Requirement already satisfied: grpc-interceptor>=0.15.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.15.4)\n",
      "Requirement already satisfied: docopt in /home/jupyter/.local/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.2.3)\n",
      "Collecting tzlocal>=1.2 (from js2py<1,>=0.74->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.26.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<=2.3.0->-r requirements.txt (line 9)) (2025.7.14)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (80.9.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.10)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.18.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from strip-hints<1,>=0.1.8->kfp<=2.3.0->-r requirements.txt (line 9)) (0.45.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.3.2->kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from typer<1.0,>=0.3.2->kfp<=2.3.0->-r requirements.txt (line 9)) (14.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.3.2->kfp<=2.3.0->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.3.2->kfp<=2.3.0->-r requirements.txt (line 9)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.3.2->kfp<=2.3.0->-r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (3.3.1)\n",
      "Downloading apache_beam-2.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_pubsub-2.18.4-py2.py3-none-any.whl (265 kB)\n",
      "Downloading google_cloud_bigquery-3.13.0-py2.py3-none-any.whl (222 kB)\n",
      "Downloading google_cloud_bigquery_storage-2.22.0-py2.py3-none-any.whl (190 kB)\n",
      "Downloading google_cloud_aiplatform-1.36.1-py2.py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_pipeline_components-0.1.4-py3-none-any.whl (81 kB)\n",
      "Downloading plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.0.1-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "Downloading google_cloud_bigtable-2.31.0-py3-none-any.whl (488 kB)\n",
      "Downloading google_cloud_datastore-2.21.0-py2.py3-none-any.whl (208 kB)\n",
      "Downloading google_cloud_language-2.17.2-py3-none-any.whl (168 kB)\n",
      "Downloading google_cloud_videointelligence-2.16.2-py3-none-any.whl (275 kB)\n",
      "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Downloading kubernetes-25.3.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Downloading pydantic-1.10.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading strip_hints-0.1.13-py3-none-any.whl (23 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: kfp, fire, google-apitools, kfp-server-api, pyjsparser\n",
      "\u001b[33m  DEPRECATION: Building 'kfp' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'kfp'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=427023 sha256=75376b761646d3245de537c8c4525b97f666a7a5a361b5f4746e25156226a086\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/c0/fc/bf0ab209fd6ae814d7efbc821076e948c3e4884f846583ab58\n",
      "\u001b[33m  DEPRECATION: Building 'fire' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'fire'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114330 sha256=3d6d14ac36cd116653f5b39708b880dc3e0d7a342414c37b4476040ef520dca5\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "\u001b[33m  DEPRECATION: Building 'google-apitools' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-apitools'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131077 sha256=b15e0afbcd918b50857a602df7fa6806093f6179cb4cb80f367780cbba3d45b9\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "\u001b[33m  DEPRECATION: Building 'kfp-server-api' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'kfp-server-api'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99777 sha256=0e645222945195e02cb14ec43a7f7ab03ab3b15aa4b8bb01f7c02b38f8e408b6\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/c5/97/d5/e8a0f596dc85f5cfe383c800fbf3e29a99853bb54e01f26fca\n",
      "\u001b[33m  DEPRECATION: Building 'pyjsparser' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyjsparser'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for pyjsparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=26010 sha256=c2e6b8f720d4235427247426cdc2874bdc8ff2a401ef2f2947b2e06128c9ece1\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
      "Successfully built kfp fire google-apitools kfp-server-api pyjsparser\n",
      "Installing collected packages: pyjsparser, uritemplate, tzlocal, strip-hints, shellingham, pydantic, pyarrow-hotfix, protobuf, plotly, jsonpickle, fire, xgboost, kfp-server-api, kfp-pipeline-spec, js2py, typer, kubernetes, google-apitools, google-api-core, google-api-python-client, apache_beam, google-cloud-videointelligence, google-cloud-pubsub, google-cloud-language, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery-storage, google-cloud-bigquery, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "\u001b[2K  Attempting uninstall: uritemplate\n",
      "\u001b[2K    Found existing installation: uritemplate 4.2.0\n",
      "\u001b[2K    Uninstalling uritemplate-4.2.0:\n",
      "\u001b[2K      Successfully uninstalled uritemplate-4.2.0\n",
      "\u001b[2K  Attempting uninstall: pydantic━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/31\u001b[0m [shellingham]\n",
      "\u001b[2K    Found existing installation: pydantic 2.11.7━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/31\u001b[0m [shellingham]\n",
      "\u001b[2K    Uninstalling pydantic-2.11.7:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/31\u001b[0m [shellingham]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.11.7━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/31\u001b[0m [shellingham]\n",
      "\u001b[2K  Attempting uninstall: protobufm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/31\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: protobuf 3.19.6━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/31\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling protobuf-3.19.6:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/31\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled protobuf-3.19.6━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/31\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: plotlym\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/31\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: plotly 5.10.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/31\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling plotly-5.10.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/31\u001b[0m [plotly]\n",
      "\u001b[2K      Successfully uninstalled plotly-5.10.0━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/31\u001b[0m [plotly]\n",
      "\u001b[2K  Attempting uninstall: xgboost[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/31\u001b[0m [fire]y]\n",
      "\u001b[2K    Found existing installation: xgboost 1.6.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/31\u001b[0m [fire]\n",
      "\u001b[2K    Uninstalling xgboost-1.6.2:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/31\u001b[0m [fire]\n",
      "\u001b[2K      Successfully uninstalled xgboost-1.6.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/31\u001b[0m [fire]\n",
      "\u001b[2K  Attempting uninstall: kfp-server-api90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/31\u001b[0m [xgboost]\n",
      "\u001b[2K    Found existing installation: kfp-server-api 2.0.5━━━━━━━━━\u001b[0m \u001b[32m11/31\u001b[0m [xgboost]\n",
      "\u001b[2K    Uninstalling kfp-server-api-2.0.5:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/31\u001b[0m [xgboost]\n",
      "\u001b[2K      Successfully uninstalled kfp-server-api-2.0.5━━━━━━━━━━━\u001b[0m \u001b[32m11/31\u001b[0m [xgboost]\n",
      "\u001b[2K  Attempting uninstall: kfp-pipeline-specm━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/31\u001b[0m [kfp-server-api]\n",
      "\u001b[2K    Found existing installation: kfp-pipeline-spec 0.2.2━━━━━━\u001b[0m \u001b[32m12/31\u001b[0m [kfp-server-api]\n",
      "\u001b[2K    Uninstalling kfp-pipeline-spec-0.2.2:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/31\u001b[0m [kfp-server-api]\n",
      "\u001b[2K      Successfully uninstalled kfp-pipeline-spec-0.2.2━━━━━━━━\u001b[0m \u001b[32m12/31\u001b[0m [kfp-server-api]\n",
      "\u001b[2K  Attempting uninstall: kubernetesm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/31\u001b[0m [js2py]peline-spec]\n",
      "\u001b[2K    Found existing installation: kubernetes 26.1.0━━━━━━━━━━━━\u001b[0m \u001b[32m14/31\u001b[0m [js2py]\n",
      "\u001b[2K    Uninstalling kubernetes-26.1.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/31\u001b[0m [js2py]\n",
      "\u001b[2K      Successfully uninstalled kubernetes-26.1.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/31\u001b[0m [js2py]\n",
      "\u001b[2K  Attempting uninstall: google-apitools[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/31\u001b[0m [kubernetes]\n",
      "\u001b[2K    Found existing installation: google-apitools 0.5.32━━━━━━━\u001b[0m \u001b[32m16/31\u001b[0m [kubernetes]\n",
      "\u001b[2K    Uninstalling google-apitools-0.5.32:90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/31\u001b[0m [kubernetes]\n",
      "\u001b[2K      Successfully uninstalled google-apitools-0.5.32━━━━━━━━━\u001b[0m \u001b[32m16/31\u001b[0m [kubernetes]\n",
      "\u001b[2K  Attempting uninstall: google-api-core\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [google-apitools]\n",
      "\u001b[2K    Found existing installation: google-api-core 2.8.2━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [google-apitools]\n",
      "\u001b[2K    Uninstalling google-api-core-2.8.2:\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [google-apitools]\n",
      "\u001b[2K      Successfully uninstalled google-api-core-2.8.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/31\u001b[0m [google-api-core]\n",
      "\u001b[2K  Attempting uninstall: google-api-python-client━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/31\u001b[0m [google-api-core]\n",
      "\u001b[2K    Found existing installation: google-api-python-client 2.123.0m \u001b[32m18/31\u001b[0m [google-api-core]\n",
      "\u001b[2K    Uninstalling google-api-python-client-2.123.0:━━━━━━━━━━━━\u001b[0m \u001b[32m18/31\u001b[0m [google-api-core]\n",
      "\u001b[2K      Successfully uninstalled google-api-python-client-2.123.0[0m \u001b[32m18/31\u001b[0m [google-api-core]\n",
      "\u001b[2K  Attempting uninstall: apache_beamm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [google-api-python-client]\n",
      "\u001b[2K    Found existing installation: apache-beam 2.40.0━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [google-api-python-client]\n",
      "\u001b[2K    Uninstalling apache-beam-2.40.0:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [google-api-python-client]\n",
      "\u001b[2K      Successfully uninstalled apache-beam-2.40.090m━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/31\u001b[0m [apache_beam]n-client]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-videointelligence━━━━━━━━━━━━\u001b[0m \u001b[32m20/31\u001b[0m [apache_beam]\n",
      "\u001b[2K    Found existing installation: google-cloud-videointelligence 1.16.32m20/31\u001b[0m [apache_beam]\n",
      "\u001b[2K    Uninstalling google-cloud-videointelligence-1.16.3:━━━━━━━\u001b[0m \u001b[32m20/31\u001b[0m [apache_beam]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-videointelligence-1.16.3 \u001b[32m21/31\u001b[0m [google-cloud-videointelligence]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-pubsub\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m21/31\u001b[0m [google-cloud-videointelligence]\n",
      "\u001b[2K    Found existing installation: google-cloud-pubsub 2.13.6━\u001b[0m \u001b[32m21/31\u001b[0m [google-cloud-videointelligence]\n",
      "\u001b[2K    Uninstalling google-cloud-pubsub-2.13.6:[90m━━━━━━━━━━━━\u001b[0m \u001b[32m21/31\u001b[0m [google-cloud-videointelligence]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-pubsub-2.13.6━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [google-cloud-pubsub]ence]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-language╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [google-cloud-pubsub]\n",
      "\u001b[2K    Found existing installation: google-cloud-language 1.3.2━━\u001b[0m \u001b[32m22/31\u001b[0m [google-cloud-pubsub]\n",
      "\u001b[2K    Uninstalling google-cloud-language-1.3.2:m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [google-cloud-pubsub]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-language-1.3.2━━━━━━━━\u001b[0m \u001b[32m23/31\u001b[0m [google-cloud-language]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-datastore╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m23/31\u001b[0m [google-cloud-language]\n",
      "\u001b[2K    Found existing installation: google-cloud-datastore 1.15.5\u001b[0m \u001b[32m23/31\u001b[0m [google-cloud-language]\n",
      "\u001b[2K    Uninstalling google-cloud-datastore-1.15.5:\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m23/31\u001b[0m [google-cloud-language]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-datastore-1.15.5━━━━━━\u001b[0m \u001b[32m24/31\u001b[0m [google-cloud-datastore]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-bigtable1m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m24/31\u001b[0m [google-cloud-datastore]\n",
      "\u001b[2K    Found existing installation: google-cloud-bigtable 1.7.3━━\u001b[0m \u001b[32m24/31\u001b[0m [google-cloud-datastore]\n",
      "\u001b[2K    Uninstalling google-cloud-bigtable-1.7.3:[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m24/31\u001b[0m [google-cloud-datastore]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-bigtable-1.7.3m━━━━━━━\u001b[0m \u001b[32m25/31\u001b[0m [google-cloud-bigtable]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-bigquery-storagem\u001b[90m━━━━━━━\u001b[0m \u001b[32m25/31\u001b[0m [google-cloud-bigtable]\n",
      "\u001b[2K    Found existing installation: google-cloud-bigquery-storage 2.16.232m25/31\u001b[0m [google-cloud-bigtable]\n",
      "\u001b[2K    Uninstalling google-cloud-bigquery-storage-2.16.2:m━━━━━━━\u001b[0m \u001b[32m25/31\u001b[0m [google-cloud-bigtable]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-bigquery-storage-2.16.20m \u001b[32m26/31\u001b[0m [google-cloud-bigquery-storage]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-bigquery[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m26/31\u001b[0m [google-cloud-bigquery-storage]\n",
      "\u001b[2K    Found existing installation: google-cloud-bigquery 3.18.0\u001b[0m \u001b[32m26/31\u001b[0m [google-cloud-bigquery-storage]\n",
      "\u001b[2K    Uninstalling google-cloud-bigquery-3.18.0:\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m26/31\u001b[0m [google-cloud-bigquery-storage]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-bigquery-3.18.0━━\u001b[0m \u001b[32m26/31\u001b[0m [google-cloud-bigquery-storage]\n",
      "\u001b[2K  Attempting uninstall: kfp━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m27/31\u001b[0m [google-cloud-bigquery]ge]\n",
      "\u001b[2K    Found existing installation: kfp 2.4.0\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m27/31\u001b[0m [google-cloud-bigquery]\n",
      "\u001b[2K    Uninstalling kfp-2.4.0:━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m28/31\u001b[0m [kfp]loud-bigquery]\n",
      "\u001b[2K      Successfully uninstalled kfp-2.4.0\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m28/31\u001b[0m [kfp]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-aiplatformm\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m28/31\u001b[0m [kfp]\n",
      "\u001b[2K    Found existing installation: google-cloud-aiplatform 1.60.0[0m \u001b[32m28/31\u001b[0m [kfp]\n",
      "\u001b[2K    Uninstalling google-cloud-aiplatform-1.60.0:m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m29/31\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-aiplatform-1.60.090m━━\u001b[0m \u001b[32m29/31\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-pipeline-components[0m\u001b[90m━━\u001b[0m \u001b[32m29/31\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K    Found existing installation: google-cloud-pipeline-components 2.8.0m29/31\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K    Uninstalling google-cloud-pipeline-components-2.8.0:[90m━━\u001b[0m \u001b[32m29/31\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-pipeline-components-2.8.032m29/31\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/31\u001b[0m [google-cloud-pipeline-components]peline-components]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "ydata-profiling 4.16.1 requires pydantic>=2, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed apache_beam-2.46.0 fire-0.7.0 google-api-core-2.25.1 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-aiplatform-1.36.1 google-cloud-bigquery-3.13.0 google-cloud-bigquery-storage-2.22.0 google-cloud-bigtable-2.31.0 google-cloud-datastore-2.21.0 google-cloud-language-2.17.2 google-cloud-pipeline-components-0.1.4 google-cloud-pubsub-2.18.4 google-cloud-videointelligence-2.16.2 js2py-0.74 jsonpickle-3.4.2 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-25.3.0 plotly-5.18.0 protobuf-3.20.3 pyarrow-hotfix-0.7 pydantic-1.10.22 pyjsparser-2.7.1 shellingham-1.5.4 strip-hints-0.1.13 typer-0.16.0 tzlocal-5.3.1 uritemplate-3.0.1 xgboost-2.0.1\n",
      "requirements installed\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade -r 'requirements.txt'\n",
    "print(\"requirements installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d07214a67580"
   },
   "source": [
    "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "18c113700b6f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f31ae3fed8ab"
   },
   "source": [
    "### Setup your environment\n",
    "\n",
    "Run the next cells to import libraries used in this notebook and configure some options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d61a362443d"
   },
   "source": [
    "Run the next cell to set your project ID and some of the other constants used in the lab.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "wxiE6dEWOFm3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Generate unique ID to help w/ unique naming of certain pieces\n",
    "ID = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=5))\n",
    "\n",
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fraudfinder\"\n",
    "REGION = \"us-central1\"\n",
    "TRAINING_DS_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd738fc1e201"
   },
   "source": [
    "### Create a Google Cloud Storage bucket and save the config data.\n",
    "\n",
    "Next, we will create a Google Cloud Storage bucket and will save the config data in this bucket. After the cell operation finishes, you can navigate to [Google Cloud Storage](https://console.cloud.google.com/storage/) to see the GCS bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7d3556c598a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-03-e4b161fbf0c8-fraudfinder/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'qwiklabs-gcp-03-e4b161fbf0c8-fraudfinder' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
      "Copying from <STDIN>...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "config = f\"\"\"\n",
    "BUCKET_NAME          = \\\"{BUCKET_NAME}\\\"\n",
    "PROJECT              = \\\"{PROJECT_ID}\\\"\n",
    "REGION               = \\\"{REGION}\\\"\n",
    "ID                   = \\\"{ID}\\\"\n",
    "FEATURESTORE_ID      = \\\"fraudfinder_{ID}\\\"\n",
    "MODEL_NAME           = \\\"ff_model\\\"\n",
    "ENDPOINT_NAME        = \\\"ff_model_endpoint\\\"\n",
    "TRAINING_DS_SIZE     = \\\"{TRAINING_DS_SIZE}\\\"\n",
    "\"\"\"\n",
    "\n",
    "!gsutil mb -l {REGION} gs://{BUCKET_NAME}\n",
    "\n",
    "!echo '{config}' | gsutil cp - gs://{BUCKET_NAME}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc2dff7ba2e0"
   },
   "source": [
    "### Copy the historical transaction data into BigQuery tables\n",
    "\n",
    "Now we will copy the historical transaction data and ingest it into BigQuery tables. For this, we will need to run `copy_bigquery_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4ac6e0bc33b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied from gs://cymbal-fraudfinder/datagen/hacked_customers_history.txt \n",
      "\t\t to gs://qwiklabs-gcp-03-e4b161fbf0c8-fraudfinder/datagen/hacked_customers_history.txt\n",
      "File copied from gs://cymbal-fraudfinder/datagen/hacked_terminals_history.txt \n",
      "\t\t to gs://qwiklabs-gcp-03-e4b161fbf0c8-fraudfinder/datagen/hacked_terminals_history.txt\n",
      "File copied from gs://cymbal-fraudfinder/datagen/demographics/customer_profiles.csv \n",
      "\t\t to gs://qwiklabs-gcp-03-e4b161fbf0c8-fraudfinder/datagen/demographics/customer_profiles.csv\n",
      "File copied from gs://cymbal-fraudfinder/datagen/demographics/terminal_profiles.csv \n",
      "\t\t to gs://qwiklabs-gcp-03-e4b161fbf0c8-fraudfinder/datagen/demographics/terminal_profiles.csv\n",
      "File copied from gs://cymbal-fraudfinder/datagen/demographics/customer_with_terminal_profiles.csv \n",
      "\t\t to gs://qwiklabs-gcp-03-e4b161fbf0c8-fraudfinder/datagen/demographics/customer_with_terminal_profiles.csv\n",
      "BigQuery table created: `qwiklabs-gcp-03-e4b161fbf0c8`.tx.tx\n",
      "BigQuery table created: `qwiklabs-gcp-03-e4b161fbf0c8`.tx.txlabels\n",
      "BigQuery table created: `qwiklabs-gcp-03-e4b161fbf0c8`.demographics.customers\n",
      "BigQuery table created: `qwiklabs-gcp-03-e4b161fbf0c8`.demographics.terminals\n",
      "BigQuery table created: `qwiklabs-gcp-03-e4b161fbf0c8`.demographics.customersterminals\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/copy_bigquery_data.py $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29dbf432339c"
   },
   "source": [
    "### Check data in BigQuery\n",
    "\n",
    "After ingesting our data into BigQuery, it's time to run some queries against the tables to inspect the data. You can also go to the [BigQuery console](https://console.cloud.google.com/bigquery) to see the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e12ec3dae852"
   },
   "source": [
    "#### Initialize BigQuery SDK for Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ace8667cc99e"
   },
   "source": [
    "Use a helper function for sending queries to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f7afa36c6090",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "# Wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
    "    Args:\n",
    "        sql: SQL query, as a string, to execute in BigQuery\n",
    "    Returns:\n",
    "        df: DataFrame of results from query,  or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client = bigquery.Client()\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    return df\n",
    "print(\"Initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20875916c5d4"
   },
   "source": [
    "#### tx.tx\n",
    "The `tx.tx` table contains the basic information about each transaction:\n",
    "- `TX_ID` is a unique ID per transaction\n",
    "- `TX_TS` is the timestamp of the transaction, in UTC\n",
    "- `CUSTOMER_ID` is a unique 16-digit string ID per customer\n",
    "- `TERMINAL_ID` is a unique 16-digit string ID per point-of-sale terminal\n",
    "- `TX_AMOUNT` is the amount of money spent by the customer at a terminal, in dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cc0e50b158d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: 075d5961-6e96-4d79-a067-0590ad974ce2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TX_ID</th>\n",
       "      <th>TX_TS</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f91897baa7086b5a8434c3cd7577dd8308aba51</td>\n",
       "      <td>2024-04-03 14:48:02+00:00</td>\n",
       "      <td>9942884307002811</td>\n",
       "      <td>00064542</td>\n",
       "      <td>64.770000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9f973615ddbf63938ab46092d148d6f651585d9f</td>\n",
       "      <td>2024-04-03 13:40:12+00:00</td>\n",
       "      <td>7655238087830723</td>\n",
       "      <td>00064542</td>\n",
       "      <td>27.580000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a4c08b0b2fb6344f77b92a2725be2734d4143d9b</td>\n",
       "      <td>2024-04-03 07:58:29+00:00</td>\n",
       "      <td>2636019257231847</td>\n",
       "      <td>00064542</td>\n",
       "      <td>11.540000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a3f6b3329bba036ac68cfca6b59ea49a9ff34307</td>\n",
       "      <td>2024-04-03 14:06:25+00:00</td>\n",
       "      <td>3608132409677363</td>\n",
       "      <td>00064542</td>\n",
       "      <td>62.590000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c449e0b98be194445734c81eb7f468b594e9f7d6</td>\n",
       "      <td>2024-04-03 09:52:25+00:00</td>\n",
       "      <td>6571832288228903</td>\n",
       "      <td>00064542</td>\n",
       "      <td>16.680000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      TX_ID                     TX_TS  \\\n",
       "0  8f91897baa7086b5a8434c3cd7577dd8308aba51 2024-04-03 14:48:02+00:00   \n",
       "1  9f973615ddbf63938ab46092d148d6f651585d9f 2024-04-03 13:40:12+00:00   \n",
       "2  a4c08b0b2fb6344f77b92a2725be2734d4143d9b 2024-04-03 07:58:29+00:00   \n",
       "3  a3f6b3329bba036ac68cfca6b59ea49a9ff34307 2024-04-03 14:06:25+00:00   \n",
       "4  c449e0b98be194445734c81eb7f468b594e9f7d6 2024-04-03 09:52:25+00:00   \n",
       "\n",
       "        CUSTOMER_ID TERMINAL_ID     TX_AMOUNT  \n",
       "0  9942884307002811    00064542  64.770000000  \n",
       "1  7655238087830723    00064542  27.580000000  \n",
       "2  2636019257231847    00064542  11.540000000  \n",
       "3  3608132409677363    00064542  62.590000000  \n",
       "4  6571832288228903    00064542  16.680000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_bq_query(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  tx.tx\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e0ab0d56773"
   },
   "source": [
    "#### tx.txlabels\n",
    "The `tx.txlabels` table contains information on whether each transation was fraud or not:\n",
    "- `TX_ID` is a unique ID per transaction\n",
    "- `TX_FRAUD` is 1 if the transaction was fraud, and 0 if the transaction was not fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c128a6c78e82",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: bf693b82-5dec-4bef-ae3e-1e154d027056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TX_ID</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6bbccebf0694b9143154a796d641e31e8457f0fa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0cb4a1f9625b9dfe22e079b60d90345e74b6ae7f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d0a70d2f0b6cdaeeaec7a83c61178055c231c3e4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41c45f795ab5e4aef6a9111f8f3112c30ae330e2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ce3dc1d77da008d6c0d82e46d4a713d21044860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      TX_ID  TX_FRAUD\n",
       "0  6bbccebf0694b9143154a796d641e31e8457f0fa         0\n",
       "1  0cb4a1f9625b9dfe22e079b60d90345e74b6ae7f         0\n",
       "2  d0a70d2f0b6cdaeeaec7a83c61178055c231c3e4         0\n",
       "3  41c45f795ab5e4aef6a9111f8f3112c30ae330e2         0\n",
       "4  8ce3dc1d77da008d6c0d82e46d4a713d21044860         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_bq_query(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  tx.txlabels\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffdfcfed70bd"
   },
   "source": [
    "### Check live streaming transactions via public Pub/Sub topics\n",
    "\n",
    "As part of the [README](README.md), you've created [subscriptions](https://console.cloud.google.com/cloudpubsub/subscription/) to public Pub/Sub topics, where there is a constant flow of new transactions. This means you have, in your own Google Cloud project, subscriptions to the public Pub/Sub topics. You will receive a Pub/Sub message in your subscription every time a new transaction is streamed into the Pub/Sub topic.\n",
    "\n",
    "There are two public Pub/Sub topics where there is a constant stream of live transactions occurring.\n",
    "\n",
    "The following Pub/Sub topics are used for transactions:\n",
    "```\n",
    "projects/cymbal-fraudfinder/topics/ff-tx\n",
    "projects/cymbal-fraudfinder/topics/ff-txlabels\n",
    "```\n",
    "\n",
    "Note: If you haven't completed the steps in the README, please make sure that you complete them first before continuing this notebook, otherwise you may not have Pub/Sub subscriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bd15fba9b30"
   },
   "source": [
    "### Reading messages from the Pub/Sub topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "544309c7c12f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_from_sub(project_id, subscription_name, messages=10):\n",
    "    \"\"\"\n",
    "    Read messages from a Pub/Sub subscription\n",
    "    Args:\n",
    "        project_id: project ID\n",
    "        subscription_name: the name of a Pub/Sub subscription in your project\n",
    "        messages: number of messages to read\n",
    "    Returns:\n",
    "        msg_data: list of messages in your Pub/Sub subscription as a Python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    import ast\n",
    "\n",
    "    from google.api_core import retry\n",
    "    from google.cloud import pubsub_v1\n",
    "\n",
    "    subscriber = pubsub_v1.SubscriberClient()\n",
    "    subscription_path = subscriber.subscription_path(project_id, subscription_name)\n",
    "\n",
    "    # Wrap the subscriber in a 'with' block to automatically call close() to\n",
    "    # close the underlying gRPC channel when done.\n",
    "    with subscriber:\n",
    "        # The subscriber pulls a specific number of messages. The actual\n",
    "        # number of messages pulled may be smaller than max_messages.\n",
    "        response = subscriber.pull(\n",
    "            subscription=subscription_path,\n",
    "            max_messages=messages,\n",
    "            retry=retry.Retry(deadline=300),\n",
    "        )\n",
    "\n",
    "        if len(response.received_messages) == 0:\n",
    "            print(\"no messages\")\n",
    "            return\n",
    "\n",
    "        ack_ids = []\n",
    "        msg_data = []\n",
    "        for received_message in response.received_messages:\n",
    "            msg = ast.literal_eval(received_message.message.data.decode(\"utf-8\"))\n",
    "            msg_data.append(msg)\n",
    "            ack_ids.append(received_message.ack_id)\n",
    "\n",
    "        # Acknowledges the received messages so they will not be sent again.\n",
    "        subscriber.acknowledge(subscription=subscription_path, ack_ids=ack_ids)\n",
    "\n",
    "        print(\n",
    "            f\"Received and acknowledged {len(response.received_messages)} messages from {subscription_path}.\"\n",
    "        )\n",
    "\n",
    "        return msg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "583454c80a46"
   },
   "source": [
    "#### Reading from the `ff-tx-sub` subscription\n",
    "\n",
    "Now let's read from the `ff-tx-sub` subscription. You should see some recent transactions (in UTC timezone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "40e3b8abc1cc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received and acknowledged 2 messages from projects/qwiklabs-gcp-03-e4b161fbf0c8/subscriptions/ff-tx-sub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TX_ID': '1fbb13fd298f576afe422a4a9cd03dc0db1ab047',\n",
       "  'TX_TS': '2025-07-29 02:18:29',\n",
       "  'CUSTOMER_ID': '8713778320589436',\n",
       "  'TERMINAL_ID': '76482153',\n",
       "  'TX_AMOUNT': 13.29},\n",
       " {'TX_ID': 'dc8d9c25c82f1a4ca894fac26e8141bb8091fd8d',\n",
       "  'TX_TS': '2025-07-29 02:18:37',\n",
       "  'CUSTOMER_ID': '9863071818591403',\n",
       "  'TERMINAL_ID': '96494192',\n",
       "  'TX_AMOUNT': 84.05}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_tx = read_from_sub(\n",
    "    project_id=PROJECT_ID, subscription_name=\"ff-tx-sub\", messages=2\n",
    ")\n",
    "\n",
    "messages_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b5f23c94328"
   },
   "source": [
    "#### Reading from the `ff-txlabels-sub` subscription\n",
    "\n",
    "We will do the same with `ff-txlabels-sub` subscription, which receives the same stream of transactions as `ff-tx-sub`, but also contain the ground-truth label, `TX_FRAUD`, if the transaction is fraudulent (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ccd79c9037b9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received and acknowledged 2 messages from projects/qwiklabs-gcp-03-e4b161fbf0c8/subscriptions/ff-txlabels-sub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TX_ID': 'f5dac3f8c21644b81c99364da13aacae2b0aa715', 'TX_FRAUD': 1},\n",
       " {'TX_ID': '7a8e123e958f9c8374d03e80675b0ae4a7aad546', 'TX_FRAUD': 0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_txlabels = read_from_sub(\n",
    "    project_id=PROJECT_ID, subscription_name=\"ff-txlabels-sub\", messages=2\n",
    ")\n",
    "\n",
    "messages_txlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de7be6182813"
   },
   "source": [
    "### END\n",
    "\n",
    "Now you can go to the next notebook `01_exploratory_data_analysis.ipynb`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00_environment_setup.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
